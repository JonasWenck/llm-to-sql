{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba21eb09-524f-4e02-8493-76caa8f2aad8",
   "metadata": {},
   "source": [
    "# Automatic Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0f6a57-1938-4d1b-a2ed-2b6495bc7b4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T13:27:55.509759Z",
     "start_time": "2024-03-17T13:27:53.780363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging face cache directory from ENV: D:\\hf_cache\n",
      "Client from ENV: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import new_zealand\n",
    "import covid\n",
    "import weather\n",
    "import phi2\n",
    "import pipsql\n",
    "import llama2\n",
    "import sqlcoder\n",
    "import gpt4\n",
    "\n",
    "models = ['llama-2', 'phi2', 'sqlcoder', 'pip-sql', 'gpt-4']\n",
    "datasets = ['new_zealand', 'covid', 'weather']\n",
    "load_dotenv()\n",
    "hf_cache_directory = os.getenv(\"HF_CACHE_DIRECTORY\")\n",
    "access_token = os.getenv(\"ACCESS_TOKEN\")\n",
    "client = os.getenv(\"CLIENT\")\n",
    "\n",
    "print(\"Hugging face cache directory from ENV: \" + str(hf_cache_directory))\n",
    "print(\"Client from ENV: \" + str(client))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a87ad-8922-4fdb-9c24-91669b009560",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-03-17T13:27:55.510764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Query generation statistics: ***\n",
      "Client: cpu\n",
      "Model: pipSQL\n",
      "Dataset: new_zealand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating response for prompt 1: How many of the usual residents of New Zealand were born in Germany?\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f8a453bbc6db49b4b4c66c84f893916c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 84.033878 seconds\n",
      "Model response:\n",
      "SELECT sum(Census_usually_resident_population_count) FROM new_zealand_birthplace_2018_census WHERE Birthplace LIKE '%Germany%'\n",
      "\n",
      "Generating response for prompt 2: In how many different regions where the usual residents of New Zealand born?\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5636a2c6f6a472982fe3a2fa8c3c48c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 84.624184 seconds\n",
      "Model response:\n",
      "SELECT count(DISTINCT Census_usually_resident_population_count) FROM new_zealand_birthplace_2018_census\n",
      "\n",
      "Generating response for prompt 3: How many percent of the usual residents of new zealand where born in New Zealand?\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a69080300c8e49a3b5dbb384750b2ba6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 85.266168 seconds\n",
      "Model response:\n",
      "SELECT CAST(COUNT(*) AS FLOAT) / NULLIF(SUM(Census_usually_resident_population_count), 0) * 100 AS percent_residents_born_in_new_zealand FROM new_zealand_birthplace_2018_census\n",
      "\n",
      "Generating response for prompt 4: In which region outside of new zealand where most usual residents of New Zealand born?\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b5be1f4765b405aa03e3c0fcdb8c223"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 85.663178 seconds\n",
      "Model response:\n",
      "SELECT T1.Birthplace FROM new_zealand_birthplace_2018_census AS T1 JOIN new_zealand_birthplace_2018_census AS T2 ON T1.Code  =  T2.Code WHERE T1.Birthplace  =  \"Otago\"\n",
      "\n",
      "Generating response for prompt 5: Which birthplace region has the highest absolute discrepancy between its amount of usual residents and the census night population?\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42df9812a71b475594efde92f1cf1459"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 91.700973 seconds\n",
      "Model response:\n",
      "SELECT TOP 1 birthplace FROM new_zealand_birthplace_2018_census ORDER BY ABS(census_usually_resident_population_count - census_night_population_count) DESC\n",
      "\n",
      "Done processing dataset new_zealand on pipSQL\n",
      "\n",
      "*** Query generation statistics: ***\n",
      "Client: cpu\n",
      "Model: pipSQL\n",
      "Dataset: new_zealand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating response for prompt 1: How many of the usual residents of New Zealand were born in Germany?\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bba307cba9034f87b4450dc19d437de5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 181.787483 seconds\n",
      "Model response:\n",
      "SELECT SUM(Census_usually_resident_population_count) FROM new_zealand_birthplace_2018_census WHERE Birthplace  =  'Germany'\n",
      "\n",
      "Generating response for prompt 2: In how many different regions where the usual residents of New Zealand born?\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b26ceb60d234cd58dfeda6f3ba329bf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 182.402053 seconds\n",
      "Model response:\n",
      "SELECT SUM(Census_usually_resident_population_count) FROM new_zealand_birthplace_2018_census\n",
      "\n",
      "Generating response for prompt 3: How many percent of the usual residents of new zealand where born in New Zealand?\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6bb998c258f4ed595255ea60ffa872c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 189.971467 seconds\n",
      "Model response:\n",
      "SELECT CAST(SUM(t1.Census_usually_resident_population_count) AS FLOAT) / NULLIF(SUM(t1.Census_night_population_count), 0) * 100 AS percentage_of_residents_born_in_new_zealand FROM new_zealand_birthplace_2018_census AS t1 WHERE t1.Birthplace  =  'New Zealand'\n",
      "\n",
      "Generating response for prompt 4: In which region outside of new zealand where most usual residents of New Zealand born?\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56942516d454400db301414d25175f96"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 183.250434 seconds\n",
      "Model response:\n",
      "SELECT sum(Census_usually_resident_population_count) FROM new_zealand_birthplace_2018_census WHERE Birthplace != 'New Zealand'\n",
      "\n",
      "Generating response for prompt 5: Which birthplace region has the highest absolute discrepancy between its amount of usual residents and the census night population?\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f0989f21852d44eba8045b0f837abb60"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 192.166018 seconds\n",
      "Model response:\n",
      "SELECT TOP 1 birthplace FROM new_zealand_birthplace_2018_census ORDER BY ABS(census_usually_resident_population_count - census_night_population_count) DESC\n",
      "\n",
      "Done processing dataset new_zealand on pipSQL\n",
      "\n",
      "*** Query generation statistics: ***\n",
      "Client: cpu\n",
      "Model: pipSQL\n",
      "Dataset: covid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating response for prompt 1: Which US state had the most corona deaths?\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "162fb396f4b3442f98a5bcb64581d5dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        if dataset == 'new_zealand':\n",
    "            ddl = new_zealand.ddl\n",
    "            prompts = new_zealand.prompts\n",
    "            additional_context = new_zealand.additional_context\n",
    "    \n",
    "        elif dataset == 'covid': \n",
    "            ddl = covid.ddl\n",
    "            prompts = covid.prompts\n",
    "            additional_context = covid.additional_context\n",
    "    \n",
    "        elif dataset == 'weather':\n",
    "            ddl = weather.ddl\n",
    "            prompts = weather.prompts\n",
    "            additional_context = weather.additional_context\n",
    "\n",
    "        # let model create all \n",
    "        if model == 'llama-2':\n",
    "            llama2.run(client, ddl, prompts, hf_cache_directory, dataset, access_token)\n",
    "            llama2.run(client, ddl, prompts, hf_cache_directory, dataset, access_token, additional_context)\n",
    "            pass\n",
    "            \n",
    "        elif model == 'phi2':\n",
    "            phi2.run(client, ddl, prompts, hf_cache_directory, dataset)\n",
    "            phi2.run(client, ddl, prompts, hf_cache_directory, dataset, additional_context)\n",
    "            pass\n",
    "\n",
    "        elif model == 'sqlcoder':\n",
    "            sqlcoder.run(client, ddl, prompts, hf_cache_directory, dataset)\n",
    "            sqlcoder.run(client, ddl, prompts, hf_cache_directory, dataset, additional_context)\n",
    "            pass\n",
    "\n",
    "        elif model == 'pip-sql':\n",
    "            pipsql.run(client, ddl, prompts, hf_cache_directory, dataset)\n",
    "            pipsql.run(client, ddl, prompts, hf_cache_directory, dataset, additional_context)\n",
    "            pass\n",
    "\n",
    "        elif model == 'gpt-4':\n",
    "            gpt4.run(client, ddl, prompts, dataset)\n",
    "            gpt4.run(client, ddl, prompts, dataset, additional_context)\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
